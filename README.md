# ğŸ¤– DocuChat - RAG-Powered Documentation Assistant

An intelligent document assistant that uses **Retrieval-Augmented Generation (RAG)**, **Large Language Models (LLMs)**, and **Hugging Face APIs** to answer questions about your documents with accurate, context-aware responses.

## ğŸŒ Live Demo

ğŸ”— **[Try it live on Render](https://docuchat-rag.onrender.com/)** 

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Flask](https://img.shields.io/badge/Flask-3.0+-green.svg)
![HuggingFace](https://img.shields.io/badge/ğŸ¤—-Hugging%20Face-yellow.svg)
![Docker](https://img.shields.io/badge/Docker-Enabled-blue.svg)
![License](https://img.shields.io/badge/License-MIT-red.svg)

## ğŸŒŸ Features

- **ğŸ“„ Multi-Format Support**: Upload PDF, DOCX, and TXT documents
- **ğŸ” Intelligent Search**: Uses FAISS vector database for semantic search
- **ğŸ¤– AI-Powered Answers**: Leverages Hugging Face LLMs (Mistral-7B by default)
- **ğŸ“š Source Citations**: Shows exact sources for each answer
- **ğŸ’¬ Conversation History**: Maintains context across questions
- **ğŸ¨ Modern UI**: Clean, responsive interface with drag-and-drop
- **âš¡ Fast Processing**: Efficient document chunking and embedding

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User      â”‚
â”‚  Interface  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Flask Backend              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   API    â”‚  â”‚   RAG    â”‚   â”‚
â”‚  â”‚ Endpointsâ”‚â—„â”€â”¤  Engine  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Embeddings  â”‚ â”‚    FAISS    â”‚ â”‚ Hugging    â”‚
â”‚   Model      â”‚ â”‚   Vector    â”‚ â”‚  Face      â”‚
â”‚ (all-MiniLM) â”‚ â”‚  Database   â”‚ â”‚   LLM      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Technology Stack

- **Backend**: Flask (Python web framework)
- **RAG Framework**: LangChain
- **Vector Database**: FAISS (Facebook AI Similarity Search)
- **Embeddings**: sentence-transformers/all-MiniLM-L6-v2
- **LLM**: Mistral-7B-Instruct-v0.2 (via Hugging Face Inference API)
- **Document Processing**: PyPDF2, python-docx
- **Frontend**: HTML, CSS, JavaScript

## ğŸ“‹ Prerequisites

- Python 3.8 or higher
- Hugging Face account (free)
- 4GB+ RAM recommended

## ğŸš€ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/neel-ofar/docuchat-rag.git
cd docuchat-rag
```

### 2. Create Virtual Environment

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Set Up Environment Variables

Create a `.env` file in the project root:

```bash
cp .env.example .env
```

Get your Hugging Face token from: https://huggingface.co/settings/tokens

Edit `.env` and add your token:
```
HUGGINGFACE_TOKEN=hf_your_actual_token_here
```

### 5. Create Required Directories

```bash
mkdir uploads templates
```

## ğŸ¯ Usage

### Starting the Application

```bash
python app.py
```

The application will start at: http://localhost:5000

### Using DocuChat

1. **Upload Documents**
   - Click or drag-and-drop PDF, DOCX, or TXT files
   - Wait for processing confirmation

2. **Ask Questions**
   - Type your question in the chat input
   - Receive AI-generated answers with source citations

3. **View Sources**
   - Each answer shows which document chunks were used
   - Click to see relevant excerpts

4. **Clear Session**
   - Reset all documents and conversation history

## ğŸ“ Project Structure

```
docuchat-rag/
â”œâ”€â”€ app.py                 # Flask application & API endpoints
â”œâ”€â”€ rag_engine.py          # RAG implementation with Hugging Face
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env.example          # Environment variables template
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html        # Frontend interface
â””â”€â”€ uploads/              # Uploaded documents (auto-created)
```

## ğŸ”§ Configuration

### Change LLM Model

Edit `rag_engine.py`:

```python
self.llm_model = "meta-llama/Llama-2-7b-chat-hf"  # Or any Hugging Face model
```

Popular alternatives:
- `mistralai/Mixtral-8x7B-Instruct-v0.1`
- `meta-llama/Llama-2-13b-chat-hf`
- `google/flan-t5-xl`

### Adjust Chunk Size

In `rag_engine.py`:

```python
self.text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,      # Increase for more context
    chunk_overlap=100,    # Overlap between chunks
)
```

### Modify Retrieval Count

Change number of retrieved chunks:

```python
docs = self.vectorstore.similarity_search(question, k=5)  # Default: 3
```

## ğŸ§ª Testing

### Sample Questions to Try

After uploading a document:

- "What is the main topic of this document?"
- "Summarize the key points"
- "What does it say about [specific topic]?"
- "Can you explain [concept] mentioned in the document?"

## ğŸ“ Learning Outcomes

This project demonstrates:

1. **RAG Architecture**: Combining retrieval and generation
2. **Vector Databases**: Using FAISS for semantic search
3. **LLM Integration**: Working with Hugging Face APIs
4. **Document Processing**: Handling multiple file formats
5. **Full-Stack Development**: Flask backend + responsive frontend
6. **AI/ML Pipeline**: End-to-end AI application workflow

## ğŸš§ Future Enhancements

- [ ] Add user authentication
- [ ] Support more document formats (Excel, PPT)
- [ ] Implement conversation memory with Redis
- [ ] Add document comparison features
- [ ] Deploy to cloud (AWS, GCP, or Heroku)
- [ ] Add multi-language support
- [ ] Implement advanced analytics dashboard
- [ ] Add export conversation as PDF

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ‘¤ Author

**Shaik Neelofar**

- LinkedIn: [linkedin.com/in/shaikneelofar-cse](https://www.linkedin.com/in/shaikneelofar-cse/)
- GitHub: [@neel-ofar](https://github.com/neel-ofar)

## ğŸ™ Acknowledgments

- Hugging Face for providing amazing models and APIs
- LangChain for the RAG framework
- FAISS team for the vector database
- Open-source community

## ğŸ“§ Contact

For questions or feedback, please reach out via:
- GitHub Issues
- LinkedIn

---

**â­ If you find this project helpful, please give it a star!**
